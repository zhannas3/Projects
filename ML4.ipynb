{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ML4.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"dR6Sn202vpRB","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.datasets import load_breast_cancer"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QzNIferZv79r","colab_type":"code","colab":{}},"cell_type":"code","source":["dataset = load_breast_cancer()\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QaUQFF6PwHLh","colab_type":"code","colab":{}},"cell_type":"code","source":["type(dataset) #0 злокачественная 1-доброкачественная"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9svsFv7owQYh","colab_type":"code","colab":{}},"cell_type":"code","source":["df = pd.DataFrame(dataset.data, columns = dataset.feature_names)  \n","df['Target'] = dataset.target   "],"execution_count":0,"outputs":[]},{"metadata":{"id":"vLsWI83owf4p","colab_type":"code","colab":{}},"cell_type":"code","source":["df.head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"lEuu4bJqwmll","colab_type":"code","colab":{}},"cell_type":"code","source":["df.shape"],"execution_count":0,"outputs":[]},{"metadata":{"id":"frEh3FwowqTM","colab_type":"code","colab":{}},"cell_type":"code","source":["def plotFeatures(X, y):\n","  plt.figure(figsize = (8,8))\n","  plt.scatter(X[y==0][:,0], X[y==0][:,1], color ='b', label ='Malignant') #zlokacahestvennaya\n","  plt.scatter(X[y==1][:,0], X[y==1][:,1], color ='r', label ='Bening') #dobrocahestvennaya\n","  plt.legend()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LveILVIgyjfs","colab_type":"code","colab":{}},"cell_type":"code","source":["import seaborn as sns\n","fig = plt.subplots(figsize =(15,15))\n","sns.heatmap(df.corr(), square =True, cbar = True, annot = True, annot_kws={'size':9})\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"PDJJUAOR0CRi","colab_type":"code","colab":{}},"cell_type":"code","source":["X = dataset.data[:, 5:7]\n","y = dataset.target"],"execution_count":0,"outputs":[]},{"metadata":{"id":"sKzPe3DW1DaY","colab_type":"code","colab":{}},"cell_type":"code","source":["def sigmoid(z):\n","  return 1/(1+np.exp(-z))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5eecG15j0Ron","colab_type":"code","colab":{}},"cell_type":"code","source":["def predict(x, theta):\n","  return sigmoid(np.dot(x,theta))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"X77CExoV0eCy","colab_type":"code","colab":{}},"cell_type":"code","source":["sigmoid(5)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gQ5RV3eg1s5s","colab_type":"code","colab":{}},"cell_type":"code","source":["def calculateCost(h,y):\n","  return (-y*np.log(h)-(1-y)*np.log(1-h)).mean()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"B8dx0DKM2-Ep","colab_type":"code","colab":{}},"cell_type":"code","source":["def plotDecisionBoundary(X,theta,y):\n","  #choose the boundaries of my grid\n","  #my input data varies between x1_min and x1_max\n","  #and x2_min and x2_max\n","  x1_min, x1_max = X[:,0].min(), X[:,0].max(),\n","  x2_min, x2_max = X[:,1].min(), X[:,1].max(),\n","  #create a grid for plotting the decision boundary\n","  xx1, xx2 = np.meshgrid(np.linspace(x1_min, x1_max), np.linspace(x2_min, x2_max))\n","  grid = np.c_[xx1.ravel(), xx2.ravel()]\n","  probabilities = predict(grid, theta).reshape(xx1.shape)\n","  #alpha is not a learning rate\n","  #alpha decides the shape of the boundary\n","  plt.contourf(xx1,xx2,probabilities, alpha = 0.5, levels = 1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cPWLOGb-5O4j","colab_type":"code","colab":{}},"cell_type":"code","source":["plotFeatures(X,y)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5P_WBVkG5inD","colab_type":"code","colab":{}},"cell_type":"code","source":["def gradientDescentLogisticRegression(alpha = 0.001, iterations = 5001):\n","  costs = []\n","  theta=np.zeros(2)\n","  for i in range(iterations):\n","    pred = predict(X,theta)\n","    theta = theta - alpha*np.dot(X.T, (pred-y))/y.size\n","    J = calculateCost(pred, y)\n","    costs.append(J)\n","    if i%(iterations//5) == 0:\n","      print(f\"Iteration: {i+1}, Cost = {J}, theta = {theta}\")\n","      plotFeatures(X,y)\n","      plotDecisionBoundary(X,theta,y)\n","      plt.show()         \n","  print(\"Cost function plot: \")\n","  plt.plot(np.linspace(0,iterations-1, num = iterations), costs)\n","  plt.xlabel('No. of iterations')\n","  plt.ylabel('J')\n","  return theta"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9K8P5KSv9dYN","colab_type":"code","colab":{}},"cell_type":"code","source":["theta = gradientDescentLogisticRegression(alpha = 0.001,iterations = 300001)"],"execution_count":0,"outputs":[]}]}